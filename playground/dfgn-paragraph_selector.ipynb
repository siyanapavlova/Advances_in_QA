{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installations done before\n",
    "    \n",
    "    pip3 install pytorch-pretrained-bert\n",
    "    pip3 install pytorch-nlp\n",
    "    pip3 install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load first query and paragraphs from HotPotQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.abspath('../data/hotpot_train_v1.1.json')) as json_file:\n",
    "    hotpot_train = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Which magazine was started first Arthur's Magazine or First for Women?\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = hotpot_train[0]['question']\n",
    "paragraphs = hotpot_train[0]['context']\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Radio City (Indian radio station)',\n",
       " [\"Radio City is India's first private FM radio station and was started on 3 July 2001.\",\n",
       "  ' It broadcasts on 91.1 (earlier 91.0 in most cities) megahertz from Mumbai (where it was started in 2004), Bengaluru (started first in 2001), Lucknow and New Delhi (since 2003).',\n",
       "  ' It plays Hindi, English and regional songs.',\n",
       "  ' It was launched in Hyderabad in March 2006, in Chennai on 7 July 2006 and in Visakhapatnam October 2007.',\n",
       "  ' Radio City recently forayed into New Media in May 2008 with the launch of a music portal - PlanetRadiocity.com that offers music related news, videos, songs, and other music-related features.',\n",
       "  ' The Radio station currently plays a mix of Hindi and Regional music.',\n",
       "  ' Abraham Thomas is the CEO of the company.']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                 output_hidden_states=True,\n",
    "                                 output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was not a puppeteer. He died too early. [SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,   101,  2040,  2001,  3958, 27227,  1029,   102,  3958, 27227,\n",
       "          2001,  2025,  1037, 13997, 11510,  1012,  2002,  2351,  2205,  2220,\n",
       "          1012,   102,   102]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_ids must be a list of lists\n",
    "input_ids = torch.tensor([tokenizer.encode(text)])\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hidden_states, all_attentions = model(input_ids)[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 23, 23])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have 12 \"attentions\" - one for each \"encoder layer\"; each of these layers\n",
    "# has 12 attention heads. Each attention head has a dimention n x n,\n",
    "# where n is the number of words in the sentence.\n",
    "all_attentions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] Radio City is India's first private FM radio station and was started on 3 July 2001. [SEP] It broadcasts on 91.1 (earlier 91.0 in most cities) megahertz from Mumbai (where it was started in 2004), Bengaluru (started first in 2001), Lucknow and New Delhi (since 2003). [SEP] It plays Hindi, English and regional songs. [SEP] It was launched in Hyderabad in March 2006, in Chennai on 7 July 2006 and in Visakhapatnam October 2007. [SEP] Radio City recently forayed into New Media in May 2008 with the launch of a music portal - PlanetRadiocity.com that offers music related news, videos, songs, and other music-related features. [SEP] The Radio station currently plays a mix of Hindi and Regional music. [SEP] Abraham Thomas is the CEO of the company. [SEP]\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add [CLS] and [SEP] to paragraph and join sentences for each paragraph together\n",
    "test_paragraph = \"[CLS] \" + (\" [SEP]\").join(paragraphs[0][1]) + \" [SEP]\"\n",
    "test_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'radio', 'city', 'is', 'india', \"'\", 's', 'first', 'private', 'fm']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_paragraph = tokenizer.tokenize(test_paragraph)\n",
    "tokenized_paragraph[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text,\n",
    "           tokenizer=BertTokenizer.from_pretrained('bert-base-uncased'),\n",
    "           model=BertModel.from_pretrained('bert-base-uncased',\n",
    "                                 output_hidden_states=True,\n",
    "                                 output_attentions=True)):\n",
    "    ''' TODO: document\n",
    "    '''\n",
    "    \n",
    "    input_ids = torch.tensor([tokenizer.encode(text)])\n",
    "    all_hidden_states, all_attentions = model(input_ids)[-2:]\n",
    "    \n",
    "    # This is the embedding of the [CLS] token.\n",
    "    # [-1] is the last hidden state (list of sentences)\n",
    "    # first [0] - first (and only) sentence\n",
    "    # second [0] - first ([CLS]) token of the sentence\n",
    "    return all_hidden_states[-1][0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paragraph selector class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParagraphSelector_non_final(torch.nn.Module):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_size=768, output_size=1):\n",
    "        self.linear  = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, embedding):\n",
    "        output = self.linear(embedding)\n",
    "        output = torch.sigmoid(output)\n",
    "        \n",
    "        return output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_data_from_filedata(hotpot_train):\n",
    "    '''\n",
    "    Make a dataframe with training data for selecting relevant paragraphs\n",
    "    Each entry in the dataframe has three columns:\n",
    "        1. Query - the question\n",
    "        2. Paragraphs - the paragraphs\n",
    "        3. Label - 0 (unrelated) or 1 (related)\n",
    "    '''\n",
    "    for item in hotpot_train[:10]:\n",
    "        query = item['question']\n",
    "        paragraphs = item['context']\n",
    "        supporting_facts = [i[0] for i in item['supporting_facts']]\n",
    "        \n",
    "        labels = []\n",
    "        datapoints = []\n",
    "        for para in paragraphs:\n",
    "            labels.append(int(para[0] in supporting_facts))\n",
    "            datapoints.append(\"[CLS] \" + query + \" [SEP] \" + (\"\").join(para[1]) + \" [SEP]\")\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'id': range(len(labels)),\n",
    "            'label': labels,\n",
    "            'text': datapoints\n",
    "        })\n",
    "        return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_training_data(hotpot_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                               text\n",
       "0   0      0  [CLS] Which magazine was started first Arthur'...\n",
       "1   1      0  [CLS] Which magazine was started first Arthur'...\n",
       "2   2      0  [CLS] Which magazine was started first Arthur'...\n",
       "3   3      0  [CLS] Which magazine was started first Arthur'...\n",
       "4   4      0  [CLS] Which magazine was started first Arthur'...\n",
       "5   5      1  [CLS] Which magazine was started first Arthur'...\n",
       "6   6      0  [CLS] Which magazine was started first Arthur'...\n",
       "7   7      1  [CLS] Which magazine was started first Arthur'...\n",
       "8   8      0  [CLS] Which magazine was started first Arthur'...\n",
       "9   9      0  [CLS] Which magazine was started first Arthur'..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] Which magazine was started first Arthur's Magazine or First for Women? [SEP] Radio City is India's first private FM radio station and was started on 3 July 2001. It broadcasts on 91.1 (earlier 91.0 in most cities) megahertz from Mumbai (where it was started in 2004), Bengaluru (started first in 2001), Lucknow and New Delhi (since 2003). It plays Hindi, English and regional songs. It was launched in Hyderabad in March 2006, in Chennai on 7 July 2006 and in Visakhapatnam October 2007. Radio City recently forayed into New Media in May 2008 with the launch of a music portal - PlanetRadiocity.com that offers music related news, videos, songs, and other music-related features. The Radio station currently plays a mix of Hindi and Regional music. Abraham Thomas is the CEO of the company. [SEP]\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "labels = []\n",
    "for point in data.loc[:,['label','text']].values:\n",
    "#     print(point)\n",
    "    train_data.append(encode(point[1]))\n",
    "    labels.append(point[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, labels, net, epochs, learning_rate=0.0001):\n",
    "    \n",
    "    # Use Binary Cross Entropy as a loss function instead of MSE\n",
    "    # There are papers on why MSE is bad for classification\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(lr=learning_rate)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    \n",
    "    # Iterate over the epochs\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch %d/%d' % (epoch + 1, epochs))\n",
    "        for inputs, label in zip(train_data, labels):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, label)\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, test_data):\n",
    "# set the model into evaluation mode and turn off autograd to save memory\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_data):\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network: %d %%' % (100 * correct / total))\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module implements the Paragraph Selector from the paper, Section 3.1\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class ParagraphSelector():\n",
    "    \"\"\"\n",
    "    TODO: write docstring\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 tokenizer=None),\n",
    "                 model=None):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \"\"\"\n",
    "        if not tokenizer:\n",
    "            self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        if not model:\n",
    "            self.model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                 output_hidden_states=True,\n",
    "                                 output_attentions=True)\n",
    "        \n",
    "        class ParagraphSelectorNet(torch.nn.Module):\n",
    "            \"\"\"\n",
    "            TODO: write docstring\n",
    "            \"\"\"\n",
    "            s\n",
    "            def __init__(self, input_size=768, output_size=1):\n",
    "                self.linear  = nn.Linear(input_size, output_size)\n",
    "\n",
    "            def forward(self, embedding):\n",
    "                output = self.linear(embedding)\n",
    "                output = torch.sigmoid(output)\n",
    "\n",
    "                return output \n",
    "            \n",
    "        self.net = ParagraphSelectorNet()\n",
    "    \n",
    "    def encode(text, tokenizer = self.tokenizer, model = self.model):\n",
    "        ''' TODO: document\n",
    "        '''\n",
    "\n",
    "        input_ids = torch.tensor([tokenizer.encode(text)])\n",
    "        all_hidden_states, all_attentions = model(input_ids)[-2:]\n",
    "\n",
    "        # This is the embedding of the [CLS] token.\n",
    "        # [-1] is the last hidden state (list of sentences)\n",
    "        # first [0] - first (and only) sentence\n",
    "        # second [0] - first ([CLS]) token of the sentence\n",
    "        return all_hidden_states[-1][0][0]\n",
    "\n",
    "    def train(self, train_data, labels, epochs, learning_rate=0.0001):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \"\"\"\n",
    "        # Use Binary Cross Entropy as a loss function instead of MSE\n",
    "        # There are papers on why MSE is bad for classification\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(lr=learning_rate)\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        print(\"Training...\")\n",
    "\n",
    "        # Iterate over the epochs\n",
    "        for epoch in range(epochs):\n",
    "            print('Epoch %d/%d' % (epoch + 1, epochs))\n",
    "            for inputs, label in zip(train_data, labels):\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.net(inputs)\n",
    "                loss = criterion(outputs, label)\n",
    "                loss.backward()\n",
    "                losses.append(loss.item())\n",
    "                optimizer.step()\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def predict(self, p):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \"\"\"\n",
    "        self.net.eval()\n",
    "        score = self.net(inputs)\n",
    "        return score\n",
    "\n",
    "    def test(self, test_data):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \"\"\"\n",
    "        # set the model into evaluation mode and turn off autograd to save memory\n",
    "        self.net.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_data):\n",
    "                images, labels = data\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print('Accuracy of the network: %d %%' % (100 * correct / total))\n",
    "        return correct / total\n",
    "    \n",
    "    def make_context(self, paragraphs, threshold):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \"\"\"\n",
    "        # TODO: write main function for building context\n",
    "        # Output:\n",
    "        # [[p1_title, [p1_s1, p1_s2 ...]],\n",
    "        #  [p2_title, [p2_s1, p2_s2, ...]],\n",
    "        #  ...]\n",
    "        context = []\n",
    "        for p in paragraphs:\n",
    "            score = self.predict(p)\n",
    "            if score > threshold:\n",
    "                context.append(p)\n",
    "        return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "from utils import HotPotDataHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = HotPotDataHandler(parent_dir + \"/data/hotpot_train_v1.1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dh.data_for_paragraph_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([\"Arthur's Magazine\", 'First for Women'],\n",
       "  \"Which magazine was started first Arthur's Magazine or First for Women?\",\n",
       "  [['Radio City (Indian radio station)',\n",
       "    [\"Radio City is India's first private FM radio station and was started on 3 July 2001.\",\n",
       "     ' It broadcasts on 91.1 (earlier 91.0 in most cities) megahertz from Mumbai (where it was started in 2004), Bengaluru (started first in 2001), Lucknow and New Delhi (since 2003).',\n",
       "     ' It plays Hindi, English and regional songs.',\n",
       "     ' It was launched in Hyderabad in March 2006, in Chennai on 7 July 2006 and in Visakhapatnam October 2007.',\n",
       "     ' Radio City recently forayed into New Media in May 2008 with the launch of a music portal - PlanetRadiocity.com that offers music related news, videos, songs, and other music-related features.',\n",
       "     ' The Radio station currently plays a mix of Hindi and Regional music.',\n",
       "     ' Abraham Thomas is the CEO of the company.']],\n",
       "   ['History of Albanian football',\n",
       "    ['Football in Albania existed before the Albanian Football Federation (FSHF) was created.',\n",
       "     \" This was evidenced by the team's registration at the Balkan Cup tournament during 1929-1931, which started in 1929 (although Albania eventually had pressure from the teams because of competition, competition started first and was strong enough in the duels) .\",\n",
       "     ' Albanian National Team was founded on June 6, 1930, but Albania had to wait 16 years to play its first international match and then defeated Yugoslavia in 1946.',\n",
       "     ' In 1932, Albania joined FIFA (during the 12–16 June convention ) And in 1954 she was one of the founding members of UEFA.']],\n",
       "   ['Echosmith',\n",
       "    ['Echosmith is an American, Corporate indie pop band formed in February 2009 in Chino, California.',\n",
       "     ' Originally formed as a quartet of siblings, the band currently consists of Sydney, Noah and Graham Sierota, following the departure of eldest sibling Jamie in late 2016.',\n",
       "     ' Echosmith started first as \"Ready Set Go!\"',\n",
       "     ' until they signed to Warner Bros.',\n",
       "     ' Records in May 2012.',\n",
       "     ' They are best known for their hit song \"Cool Kids\", which reached number 13 on the \"Billboard\" Hot 100 and was certified double platinum by the RIAA with over 1,200,000 sales in the United States and also double platinum by ARIA in Australia.',\n",
       "     ' The song was Warner Bros.',\n",
       "     \" Records' fifth-biggest-selling-digital song of 2014, with 1.3 million downloads sold.\",\n",
       "     ' The band\\'s debut album, \"Talking Dreams\", was released on October 8, 2013.']],\n",
       "   [\"Women's colleges in the Southern United States\",\n",
       "    [\"Women's colleges in the Southern United States refers to undergraduate, bachelor's degree–granting institutions, often liberal arts colleges, whose student populations consist exclusively or almost exclusively of women, located in the Southern United States.\",\n",
       "     \" Many started first as girls' seminaries or academies.\",\n",
       "     ' Salem College is the oldest female educational institution in the South and Wesleyan College is the first that was established specifically as a college for women.',\n",
       "     ' Some schools, such as Mary Baldwin University and Salem College, offer coeducational courses at the graduate level.']],\n",
       "   ['First Arthur County Courthouse and Jail',\n",
       "    ['The First Arthur County Courthouse and Jail, was perhaps the smallest court house in the United States, and serves now as a museum.']],\n",
       "   [\"Arthur's Magazine\",\n",
       "    [\"Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.\",\n",
       "     ' Edited by T.S. Arthur, it featured work by Edgar A. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G. Spear, and others.',\n",
       "     ' In May 1846 it was merged into \"Godey\\'s Lady\\'s Book\".']],\n",
       "   ['2014–15 Ukrainian Hockey Championship',\n",
       "    ['The 2014–15 Ukrainian Hockey Championship was the 23rd season of the Ukrainian Hockey Championship.',\n",
       "     ' Only four teams participated in the league this season, because of the instability in Ukraine and that most of the clubs had economical issues.',\n",
       "     ' Generals Kiev was the only team that participated in the league the previous season, and the season started first after the year-end of 2014.',\n",
       "     ' The regular season included just 12 rounds, where all the teams went to the semifinals.',\n",
       "     ' In the final, ATEK Kiev defeated the regular season winner HK Kremenchuk.']],\n",
       "   ['First for Women',\n",
       "    [\"First for Women is a woman's magazine published by Bauer Media Group in the USA.\",\n",
       "     ' The magazine was started in 1989.',\n",
       "     ' It is based in Englewood Cliffs, New Jersey.',\n",
       "     ' In 2011 the circulation of the magazine was 1,310,696 copies.']],\n",
       "   ['Freeway Complex Fire',\n",
       "    ['The Freeway Complex Fire was a 2008 wildfire in the Santa Ana Canyon area of Orange County, California.',\n",
       "     ' The fire started as two separate fires on November 15, 2008.',\n",
       "     ' The \"Freeway Fire\" started first shortly after 9am with the \"Landfill Fire\" igniting approximately 2 hours later.',\n",
       "     ' These two separate fires merged a day later and ultimately destroyed 314 residences in Anaheim Hills and Yorba Linda.']],\n",
       "   ['William Rast',\n",
       "    ['William Rast is an American clothing line founded by Justin Timberlake and Trace Ayala.',\n",
       "     ' It is most known for their premium jeans.',\n",
       "     ' On October 17, 2006, Justin Timberlake and Trace Ayala put on their first fashion show to launch their new William Rast clothing line.',\n",
       "     ' The label also produces other clothing items such as jackets and tops.',\n",
       "     ' The company started first as a denim line, later evolving into a men’s and women’s clothing line.']]])]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_data(data):\n",
    "    '''\n",
    "    Make a dataframe with training data for selecting relevant paragraphs\n",
    "    Each entry in the dataframe has three columns:\n",
    "        1. Query - the question\n",
    "        2. Paragraphs - the paragraphs\n",
    "        3. Label - 0 (unrelated) or 1 (related)\n",
    "    '''\n",
    "    for point in data:        \n",
    "        labels = []\n",
    "        datapoints = []\n",
    "        for para in point[2]:\n",
    "            labels.append(int(para[0] in point[0])) # Label 1: if paragraph title is in supporting facts, otherwise 0\n",
    "            datapoints.append(\"[CLS] \" + query + \" [SEP] \" + (\"\").join(para[1]) + \" [SEP]\")\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'id': range(len(labels)),\n",
    "            'label': labels,\n",
    "            'text': datapoints\n",
    "        })\n",
    "        return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Which magazine was started first Arthur'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                               text\n",
       "0   0      0  [CLS] Which magazine was started first Arthur'...\n",
       "1   1      0  [CLS] Which magazine was started first Arthur'...\n",
       "2   2      0  [CLS] Which magazine was started first Arthur'...\n",
       "3   3      0  [CLS] Which magazine was started first Arthur'...\n",
       "4   4      0  [CLS] Which magazine was started first Arthur'...\n",
       "5   5      1  [CLS] Which magazine was started first Arthur'...\n",
       "6   6      0  [CLS] Which magazine was started first Arthur'...\n",
       "7   7      1  [CLS] Which magazine was started first Arthur'...\n",
       "8   8      0  [CLS] Which magazine was started first Arthur'...\n",
       "9   9      0  [CLS] Which magazine was started first Arthur'..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_training_data(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
