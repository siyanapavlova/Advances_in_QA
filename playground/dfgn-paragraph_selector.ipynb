{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installations done before\n",
    "    \n",
    "    pip3 install pytorch-pretrained-bert\n",
    "    pip3 install pytorch-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenized input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'who',\n",
       " 'was',\n",
       " 'jim',\n",
       " 'henson',\n",
       " '?',\n",
       " '[SEP]',\n",
       " 'jim',\n",
       " 'henson',\n",
       " 'was',\n",
       " 'a',\n",
       " 'puppet',\n",
       " '##eer',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paragraph Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_context(paragraphs, query, treshold=0.1):\n",
    "    '''Takes a list of paragraphs, a query and a treshold relevance score\n",
    "    and produces a context - a list consisting of all paragraphs whose relevance\n",
    "    score to the query is higher than the treshold\n",
    "    Parameters: paragraphs - a list of strings, each representing a paragraph\n",
    "                query - a string representing the question (query)\n",
    "                treshold - a treshold relevance score\n",
    "    Output:     context - a list of relevant paragraphs\n",
    "    '''\n",
    "    context = []\n",
    "    for para in paragraphs:\n",
    "        # BERTify p+query\n",
    "        \n",
    "        # Sentence classification layer with sigmoid prediction\n",
    "        \n",
    "        # if score for para is more than r (default of treshold = 0.1), add p to context\n",
    "        if r > treshold:\n",
    "            context.append(para)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_graph(context):\n",
    "    ''' Takes a context as a list of a paragraphs, applies NER and contrsucts\n",
    "    a graph with the following type of links:\n",
    "        - sentence-level links - between pairs of entities in the same sentence\n",
    "        - context-leve links - between different occurences of the same entity\n",
    "        - paragraph-level links - [TODO - describe these]\n",
    "    Parameters: context - a list of strings, each representing a paragraph\n",
    "    Output:     graph - the produced graph [TODO - add more detail here]\n",
    "    '''\n",
    "    # Would need NER but also sentence tokenization\n",
    "    # TODO - think of an appropriate data structure for the graph\n",
    "    for para in context:\n",
    "        # apply NER to para\n",
    "        \n",
    "        # apply sentence tokenization to para\n",
    "        \n",
    "        \n",
    "        pass\n",
    "    return graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
