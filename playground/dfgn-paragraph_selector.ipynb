{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installations done before\n",
    "    \n",
    "    pip3 install pytorch-pretrained-bert\n",
    "    pip3 install pytorch-nlp\n",
    "    pip3 install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "from utils import HotPotDataHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text,\n",
    "           tokenizer=BertTokenizer.from_pretrained('bert-base-uncased'),\n",
    "           model=BertModel.from_pretrained('bert-base-uncased',\n",
    "                                 output_hidden_states=True,\n",
    "                                 output_attentions=True)):\n",
    "    ''' TODO: document\n",
    "    '''\n",
    "    \n",
    "    input_ids = torch.tensor([tokenizer.encode(text)])\n",
    "    all_hidden_states, all_attentions = model(input_ids)[-2:]\n",
    "    \n",
    "    # This is the embedding of the [CLS] token.\n",
    "    # [-1] is the last hidden state (list of sentences)\n",
    "    # first [0] - first (and only) sentence\n",
    "    # second [0] - first ([CLS]) token of the sentence\n",
    "    return all_hidden_states[-1][0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paragraph Selector Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module implements the Paragraph Selector from the paper, Section 3.1\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class ParagraphSelector():\n",
    "    \"\"\"\n",
    "    TODO: write docstring\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 model_path=None,\n",
    "                 tokenizer=None,\n",
    "                 model=None):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \"\"\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') if not tokenizer else tokenizer\n",
    "        self.model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                 output_hidden_states=True,\n",
    "                                 output_attentions=True) if not model else model\n",
    "        \n",
    "        class ParagraphSelectorNet(torch.nn.Module):\n",
    "            \"\"\"\n",
    "            TODO: write docstring\n",
    "            \"\"\"\n",
    "            def __init__(self, input_size=768, output_size=1):\n",
    "                super(ParagraphSelectorNet, self).__init__()\n",
    "                self.linear  = torch.nn.Linear(input_size, output_size)\n",
    "\n",
    "            def forward(self, embedding):\n",
    "                output = self.linear(embedding)\n",
    "                output = torch.sigmoid(output)\n",
    "\n",
    "                return output \n",
    "            \n",
    "        self.net = ParagraphSelectorNet()\n",
    "        if model_path:\n",
    "            try:\n",
    "                self.net.load_state_dict(torch.load(model_path))\n",
    "            except FileNotFoundError as e:\n",
    "                print(e, model_path)\n",
    "    \n",
    "    def encode(self, text):\n",
    "        ''' TODO: document\n",
    "        '''\n",
    "\n",
    "        input_ids = torch.tensor([self.tokenizer.encode(text)])\n",
    "        all_hidden_states, all_attentions = self.model(input_ids)[-2:]\n",
    "\n",
    "        # This is the embedding of the [CLS] token.\n",
    "        # [-1] is the last hidden state (list of sentences)\n",
    "        # first [0] - first (and only) sentence\n",
    "        # second [0] - first ([CLS]) token of the sentence\n",
    "        return all_hidden_states[-1][0][0]\n",
    "\n",
    "    def train(self, train_data, labels, epochs, learning_rate=0.0001):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \"\"\"\n",
    "        # Use Binary Cross Entropy as a loss function instead of MSE\n",
    "        # There are papers on why MSE is bad for classification\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), lr=learning_rate)\n",
    "\n",
    "        losses = []\n",
    "        \n",
    "        # Set the network into train mode\n",
    "        self.net.train()\n",
    "\n",
    "        print(\"Training...\")\n",
    "\n",
    "        # Iterate over the epochs\n",
    "        for epoch in range(epochs):\n",
    "            print('Epoch %d/%d' % (epoch + 1, epochs))\n",
    "            for inputs, label in zip(train_data, labels):\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.net(inputs)\n",
    "                loss = criterion(outputs, label)\n",
    "                loss.backward(retain_graph=True)\n",
    "                losses.append(loss.item())\n",
    "                optimizer.step()\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def predict(self, p):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \"\"\"\n",
    "        self.net.eval()\n",
    "        score = self.net(p)\n",
    "        return score\n",
    "\n",
    "    def evaluate(self, data, threshold=0.1):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \"\"\"\n",
    "        all_true = []\n",
    "        all_pred = []\n",
    "        ids = []\n",
    "        \n",
    "        for point in data:\n",
    "            context = self.make_context(point, threshold) #point[2] are the paragraphs, point[1] is the query\n",
    "            para_true = []\n",
    "            para_pred = []\n",
    "            for para in point[3]:\n",
    "                para_true.append(para[0] in point[1])\n",
    "                para_pred.append(para in context)\n",
    "            all_true.append(para_true)\n",
    "            all_pred.append(para_pred)\n",
    "            ids.append(point[0])\n",
    "        \n",
    "        # Flatten the lists so they can be passed to the precision and recall funtions\n",
    "        all_true_flattened = [point for para in all_true for point in para]\n",
    "        all_pred_flattened = [point for para in all_pred for point in para]\n",
    "        \n",
    "        precision = precision_score(all_true_flattened, all_pred_flattened)\n",
    "        recall = recall_score(all_true_flattened, all_pred_flattened)\n",
    "        \n",
    "        return precision, recall, ids, all_true, all_pred\n",
    "    \n",
    "    def make_context(self, datapoint, threshold=0.1):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \n",
    "        Parameters: paragraphs - [[p1_title, [p1_s1, p1_s2 ...]],\n",
    "                                  [p2_title, [p2_s1, p2_s2, ...]],\n",
    "                                   ...]\n",
    "                    query - the query as a string\n",
    "                    threshold - a float between zero and one;\n",
    "                                paragraphs that get a score above the\n",
    "                                threshold, become part of the context\n",
    "        Output: context: [[p1_title, [p1_s1, p1_s2 ...]],\n",
    "                          [p2_title, [p2_s1, p2_s2, ...]],\n",
    "                           ...]\n",
    "        \"\"\"\n",
    "        context = []\n",
    "        for p in datapoint[3]:\n",
    "            # p[0] is the paragraph title, p[1] is the list of sentences in the paragraph\n",
    "            encoded_p = self.encode(\"[CLS] \" + datapoint[2] + \" [SEP] \" + (\"\").join(p[1]) + \" [SEP]\")\n",
    "            score = self.predict(encoded_p)\n",
    "            if score > threshold:\n",
    "                context.append(p)\n",
    "        return context\n",
    "    \n",
    "    def save(self, savepath):\n",
    "        '''\n",
    "        TODO: write docstring\n",
    "        '''\n",
    "        directory_name = \"/\".join(savepath.split('/')[:-1])\n",
    "        print(directory_name)\n",
    "        if not os.path.exists(directory_name):\n",
    "            os.makedirs(directory_name)\n",
    "        torch.save(self.net.state_dict(), savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = HotPotDataHandler(parent_dir + \"/data/hotpot_train_v1.1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dh.data_for_paragraph_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_data(data,\n",
    "                       tokenizer=BertTokenizer.from_pretrained('bert-base-uncased'),\n",
    "                       model=BertModel.from_pretrained('bert-base-uncased',\n",
    "                                 output_hidden_states=True,\n",
    "                                 output_attentions=True)):\n",
    "    '''\n",
    "    Make a dataframe with training data for selecting relevant paragraphs\n",
    "    Each entry in the dataframe has three columns:\n",
    "        1. Query - the question\n",
    "        2. Paragraphs - the paragraphs\n",
    "        3. Label - 0 (unrelated) or 1 (related)\n",
    "    '''\n",
    "    labels = []\n",
    "    datapoints = []\n",
    "    for point in data:        \n",
    "        for para in point[3]:\n",
    "            labels.append(torch.Tensor([int(para[0] in point[1])])) # Label 1: if paragraph title is in supporting facts, otherwise 0\n",
    "            encoded_point = encode(\"[CLS] \" + point[2] + \" [SEP] \" + (\"\").join(para[1]) + \" [SEP]\", tokenizer, model)\n",
    "            datapoints.append(encoded_point)\n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "        'id': range(len(labels)),\n",
    "        'label': labels,\n",
    "        'text': datapoints\n",
    "    })\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Splitting data...\n",
      "Initilising ParagraphSelector...\n",
      "Training...\n",
      "Epoch 1/1\n",
      "Evaluating...\n",
      "Precision: 0.2\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading data...\")\n",
    "dh = HotPotDataHandler(parent_dir + \"/data/hotpot_train_v1.1.json\")\n",
    "data = dh.data_for_paragraph_selector()\n",
    "\n",
    "print(\"Splitting data...\")\n",
    "training_data_raw, test_data_raw = train_test_split(data[:4], test_size=0.25, random_state=42, shuffle=True)\n",
    "training_data = make_training_data(training_data_raw)\n",
    "training_data = shuffle(training_data, random_state=42)\n",
    "\n",
    "print(\"Initilising ParagraphSelector...\")\n",
    "ps = ParagraphSelector()\n",
    "losses = ps.train(training_data[\"text\"], training_data[\"label\"], 1)\n",
    "\n",
    "print(\"Evaluating...\")\n",
    "precision, recall, ids, y_true, y_pred = ps.evaluate(test_data_raw)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.0142, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "      <td>[tensor(-0.4818, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "      <td>[tensor(-0.0365, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "      <td>[tensor(-0.4297, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.8046, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.5943, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.3586, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "      <td>[tensor(-0.3114, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.1670, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.1817, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "      <td>[tensor(-0.6894, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.6392, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "      <td>[tensor(-0.3911, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(0.2380, grad_fn=&lt;SelectBackward&gt;), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.0445, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.1094, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(0.1476, grad_fn=&lt;SelectBackward&gt;), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.6847, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.6722, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.3263, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.1060, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.0798, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(0.2227, grad_fn=&lt;SelectBackward&gt;), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(0.1563, grad_fn=&lt;SelectBackward&gt;), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.0921, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.4255, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.7114, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.6326, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(0.0597, grad_fn=&lt;SelectBackward&gt;), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.4104, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id         label                                               text\n",
       "27  27  [tensor(0.)]  [tensor(-0.0142, grad_fn=<SelectBackward>), te...\n",
       "15  15  [tensor(1.)]  [tensor(-0.4818, grad_fn=<SelectBackward>), te...\n",
       "23  23  [tensor(1.)]  [tensor(-0.0365, grad_fn=<SelectBackward>), te...\n",
       "17  17  [tensor(1.)]  [tensor(-0.4297, grad_fn=<SelectBackward>), te...\n",
       "8    8  [tensor(0.)]  [tensor(-0.8046, grad_fn=<SelectBackward>), te...\n",
       "9    9  [tensor(0.)]  [tensor(-0.5943, grad_fn=<SelectBackward>), te...\n",
       "28  28  [tensor(0.)]  [tensor(-0.3586, grad_fn=<SelectBackward>), te...\n",
       "24  24  [tensor(1.)]  [tensor(-0.3114, grad_fn=<SelectBackward>), te...\n",
       "12  12  [tensor(0.)]  [tensor(-0.1670, grad_fn=<SelectBackward>), te...\n",
       "0    0  [tensor(0.)]  [tensor(-0.1817, grad_fn=<SelectBackward>), te...\n",
       "4    4  [tensor(1.)]  [tensor(-0.6894, grad_fn=<SelectBackward>), te...\n",
       "16  16  [tensor(0.)]  [tensor(-0.6392, grad_fn=<SelectBackward>), te...\n",
       "5    5  [tensor(1.)]  [tensor(-0.3911, grad_fn=<SelectBackward>), te...\n",
       "13  13  [tensor(0.)]  [tensor(0.2380, grad_fn=<SelectBackward>), ten...\n",
       "11  11  [tensor(0.)]  [tensor(-0.0445, grad_fn=<SelectBackward>), te...\n",
       "22  22  [tensor(0.)]  [tensor(-0.1094, grad_fn=<SelectBackward>), te...\n",
       "1    1  [tensor(0.)]  [tensor(0.1476, grad_fn=<SelectBackward>), ten...\n",
       "2    2  [tensor(0.)]  [tensor(-0.6847, grad_fn=<SelectBackward>), te...\n",
       "25  25  [tensor(0.)]  [tensor(-0.6722, grad_fn=<SelectBackward>), te...\n",
       "3    3  [tensor(0.)]  [tensor(-0.3263, grad_fn=<SelectBackward>), te...\n",
       "21  21  [tensor(0.)]  [tensor(-0.1060, grad_fn=<SelectBackward>), te...\n",
       "26  26  [tensor(0.)]  [tensor(-0.0798, grad_fn=<SelectBackward>), te...\n",
       "18  18  [tensor(0.)]  [tensor(0.2227, grad_fn=<SelectBackward>), ten...\n",
       "29  29  [tensor(0.)]  [tensor(0.1563, grad_fn=<SelectBackward>), ten...\n",
       "20  20  [tensor(0.)]  [tensor(-0.0921, grad_fn=<SelectBackward>), te...\n",
       "7    7  [tensor(0.)]  [tensor(-0.4255, grad_fn=<SelectBackward>), te...\n",
       "10  10  [tensor(0.)]  [tensor(-0.7114, grad_fn=<SelectBackward>), te...\n",
       "14  14  [tensor(0.)]  [tensor(-0.6326, grad_fn=<SelectBackward>), te...\n",
       "19  19  [tensor(0.)]  [tensor(0.0597, grad_fn=<SelectBackward>), ten...\n",
       "6    6  [tensor(0.)]  [tensor(-0.4104, grad_fn=<SelectBackward>), te..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Peggy Seeger', 'Peggy Seeger', 'Ewan MacColl'],\n",
       "  \" What nationality was James Henry Miller's wife?\",\n",
       "  [['Moloch: or, This Gentile World',\n",
       "    ['Moloch: or, This Gentile World is a semi-autobiographical novel written by Henry Miller in 1927-28, initially under the guise of a novel written by his wife, June.',\n",
       "     ' The book went unpublished until 1992, 65 years after it was written and 12 years after Miller’s death.',\n",
       "     ' It is widely considered to be of interest more as a study of Miller’s artistic growth than as a worthy piece of fiction.']],\n",
       "   ['Launceston by-election, 1874',\n",
       "    ['The Launceston by-election of 1874 was fought on 3 July 1874.',\n",
       "     ' The byelection was fought due to the void Election of the incumbent Conservative MP, James Henry Deakin (senior).',\n",
       "     ' It was won by the Conservative candidate James Henry Deakin (junior).']],\n",
       "   ['Incest: From a Journal of Love',\n",
       "    ['Incest: From a Journal of Love: The Unexpurgated Diary of Anaïs Nin (1932–1934) is a 1992 non-fiction book by Anaïs Nin.',\n",
       "     ' It is a continuation of the diary entries first published in \"Henry and June: From the Unexpurgated Diary of Anaïs Nin\".',\n",
       "     \" It features Nin's relationships with writer Henry Miller, his wife June Miller, the psychoanalyst Otto Rank, her father Joaquín Nin, and her husband Hugh Parker Guiler.\",\n",
       "     ' She also copied some of her correspondence with these people into her diary.',\n",
       "     ' Much of this book was written in English, although those of her letters which were originally written in French and Spanish were translated.',\n",
       "     ' Most of this diary takes place in France, particularly Clichy, Paris and Louveciennes.']],\n",
       "   ['James Henry Deakin (junior)',\n",
       "    ['James Henry Deakin (1851 – 8 November 1881) was a British Conservative politician, the son of Col. James Henry Deakin, a Manchester merchant.']],\n",
       "   ['Ewan MacColl',\n",
       "    ['James Henry Miller (25 January 1915 – 22 October 1989), better known by his stage name Ewan MacColl, was an English folk singer, songwriter, communist, labour activist, actor, poet, playwright and record producer.']],\n",
       "   ['Peggy Seeger',\n",
       "    ['Margaret \"Peggy\" Seeger (born June 17, 1935) is an American folksinger.',\n",
       "     ' She is also well known in Britain, where she has lived for more than 30 years, and was married to the singer and songwriter Ewan MacColl until his death in 1989.']],\n",
       "   ['Henry Miller Memorial Library',\n",
       "    ['The Henry Miller Memorial Library is a nonprofit arts center, bookstore, and performance venue, championing the late writer, artist, and Big Sur resident Henry Miller, as well as many other, both living and dead, creative individuals living in or near Big Sur, California.',\n",
       "     ' Henry Miller’s friend Emil White built the house that is now the Library in the mid-1960s.',\n",
       "     ' After Miller died, in 1980, Emil decided to maintain his property as a memorial to his friend and as a gallery where local artists could show their work.',\n",
       "     ' In 1981 Emil White, with the help of the Big Sur Land Trust, created \"The Henry Miller Memorial Library, Founded by Emil White.\"']],\n",
       "   ['June Miller',\n",
       "    ['June Miller (January 7 or 28, 1902 – February 1, 1979) was the much-written-about second wife of Henry Miller.']],\n",
       "   ['James Innes-Ker, 7th Duke of Roxburghe',\n",
       "    ['James Henry Robert Innes-Ker, 7th Duke of Roxburghe (5 September 1839 – 23 October 1892), became Duke of Roxburghe on the death of his father, James Henry Robert Innes-Ker, 6th Duke of Roxburghe.']],\n",
       "   ['Jim Miller (Australian footballer, born 1919)',\n",
       "    ['James Henry Miller (born 30 May 1919) is a former Australian rules footballer in the Victorian Football League (VFL).']]]),\n",
       " ([\"Arthur's Magazine\", 'First for Women'],\n",
       "  \"Which magazine was started first Arthur's Magazine or First for Women?\",\n",
       "  [['Radio City (Indian radio station)',\n",
       "    [\"Radio City is India's first private FM radio station and was started on 3 July 2001.\",\n",
       "     ' It broadcasts on 91.1 (earlier 91.0 in most cities) megahertz from Mumbai (where it was started in 2004), Bengaluru (started first in 2001), Lucknow and New Delhi (since 2003).',\n",
       "     ' It plays Hindi, English and regional songs.',\n",
       "     ' It was launched in Hyderabad in March 2006, in Chennai on 7 July 2006 and in Visakhapatnam October 2007.',\n",
       "     ' Radio City recently forayed into New Media in May 2008 with the launch of a music portal - PlanetRadiocity.com that offers music related news, videos, songs, and other music-related features.',\n",
       "     ' The Radio station currently plays a mix of Hindi and Regional music.',\n",
       "     ' Abraham Thomas is the CEO of the company.']],\n",
       "   ['History of Albanian football',\n",
       "    ['Football in Albania existed before the Albanian Football Federation (FSHF) was created.',\n",
       "     \" This was evidenced by the team's registration at the Balkan Cup tournament during 1929-1931, which started in 1929 (although Albania eventually had pressure from the teams because of competition, competition started first and was strong enough in the duels) .\",\n",
       "     ' Albanian National Team was founded on June 6, 1930, but Albania had to wait 16 years to play its first international match and then defeated Yugoslavia in 1946.',\n",
       "     ' In 1932, Albania joined FIFA (during the 12–16 June convention ) And in 1954 she was one of the founding members of UEFA.']],\n",
       "   ['Echosmith',\n",
       "    ['Echosmith is an American, Corporate indie pop band formed in February 2009 in Chino, California.',\n",
       "     ' Originally formed as a quartet of siblings, the band currently consists of Sydney, Noah and Graham Sierota, following the departure of eldest sibling Jamie in late 2016.',\n",
       "     ' Echosmith started first as \"Ready Set Go!\"',\n",
       "     ' until they signed to Warner Bros.',\n",
       "     ' Records in May 2012.',\n",
       "     ' They are best known for their hit song \"Cool Kids\", which reached number 13 on the \"Billboard\" Hot 100 and was certified double platinum by the RIAA with over 1,200,000 sales in the United States and also double platinum by ARIA in Australia.',\n",
       "     ' The song was Warner Bros.',\n",
       "     \" Records' fifth-biggest-selling-digital song of 2014, with 1.3 million downloads sold.\",\n",
       "     ' The band\\'s debut album, \"Talking Dreams\", was released on October 8, 2013.']],\n",
       "   [\"Women's colleges in the Southern United States\",\n",
       "    [\"Women's colleges in the Southern United States refers to undergraduate, bachelor's degree–granting institutions, often liberal arts colleges, whose student populations consist exclusively or almost exclusively of women, located in the Southern United States.\",\n",
       "     \" Many started first as girls' seminaries or academies.\",\n",
       "     ' Salem College is the oldest female educational institution in the South and Wesleyan College is the first that was established specifically as a college for women.',\n",
       "     ' Some schools, such as Mary Baldwin University and Salem College, offer coeducational courses at the graduate level.']],\n",
       "   ['First Arthur County Courthouse and Jail',\n",
       "    ['The First Arthur County Courthouse and Jail, was perhaps the smallest court house in the United States, and serves now as a museum.']],\n",
       "   [\"Arthur's Magazine\",\n",
       "    [\"Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.\",\n",
       "     ' Edited by T.S. Arthur, it featured work by Edgar A. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G. Spear, and others.',\n",
       "     ' In May 1846 it was merged into \"Godey\\'s Lady\\'s Book\".']],\n",
       "   ['2014–15 Ukrainian Hockey Championship',\n",
       "    ['The 2014–15 Ukrainian Hockey Championship was the 23rd season of the Ukrainian Hockey Championship.',\n",
       "     ' Only four teams participated in the league this season, because of the instability in Ukraine and that most of the clubs had economical issues.',\n",
       "     ' Generals Kiev was the only team that participated in the league the previous season, and the season started first after the year-end of 2014.',\n",
       "     ' The regular season included just 12 rounds, where all the teams went to the semifinals.',\n",
       "     ' In the final, ATEK Kiev defeated the regular season winner HK Kremenchuk.']],\n",
       "   ['First for Women',\n",
       "    [\"First for Women is a woman's magazine published by Bauer Media Group in the USA.\",\n",
       "     ' The magazine was started in 1989.',\n",
       "     ' It is based in Englewood Cliffs, New Jersey.',\n",
       "     ' In 2011 the circulation of the magazine was 1,310,696 copies.']],\n",
       "   ['Freeway Complex Fire',\n",
       "    ['The Freeway Complex Fire was a 2008 wildfire in the Santa Ana Canyon area of Orange County, California.',\n",
       "     ' The fire started as two separate fires on November 15, 2008.',\n",
       "     ' The \"Freeway Fire\" started first shortly after 9am with the \"Landfill Fire\" igniting approximately 2 hours later.',\n",
       "     ' These two separate fires merged a day later and ultimately destroyed 314 residences in Anaheim Hills and Yorba Linda.']],\n",
       "   ['William Rast',\n",
       "    ['William Rast is an American clothing line founded by Justin Timberlake and Trace Ayala.',\n",
       "     ' It is most known for their premium jeans.',\n",
       "     ' On October 17, 2006, Justin Timberlake and Trace Ayala put on their first fashion show to launch their new William Rast clothing line.',\n",
       "     ' The label also produces other clothing items such as jackets and tops.',\n",
       "     ' The company started first as a denim line, later evolving into a men’s and women’s clothing line.']]]),\n",
       " (['Allie Goertz', 'Allie Goertz', 'Allie Goertz', 'Milhouse Van Houten'],\n",
       "  'Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?',\n",
       "  [['Lisa Simpson',\n",
       "    ['Lisa Marie Simpson is a fictional character in the animated television series \"The Simpsons\".',\n",
       "     ' She is the middle child and most intelligent of the Simpson family.',\n",
       "     ' Voiced by Yeardley Smith, Lisa first appeared on television in \"The Tracey Ullman Show\" short \"Good Night\" on April 19, 1987.',\n",
       "     ' Cartoonist Matt Groening created and designed her while waiting to meet James L. Brooks.',\n",
       "     ' Groening had been invited to pitch a series of shorts based on his comic \"Life in Hell\", but instead decided to create a new set of characters.',\n",
       "     ' He named the elder Simpson daughter after his younger sister Lisa Groening.',\n",
       "     ' After appearing on \"The Tracey Ullman Show\" for three years, the Simpson family were moved to their own series on Fox, which debuted on December 17, 1989.']],\n",
       "   ['Marge Simpson',\n",
       "    ['Marjorie Jacqueline \"Marge\" Simpson (née Bouvier) is a fictional character in the American animated sitcom \"The Simpsons\" and part of the eponymous family.',\n",
       "     ' She is voiced by Julie Kavner and first appeared on television in \"The Tracey Ullman Show\" short \"Good Night\" on April 19, 1987.',\n",
       "     \" Marge was created and designed by cartoonist Matt Groening while he was waiting in the lobby of James L. Brooks' office.\",\n",
       "     ' Groening had been called to pitch a series of shorts based on \"Life in Hell\" but instead decided to create a new set of characters.',\n",
       "     ' He named the character after his mother Margaret Groening.',\n",
       "     ' After appearing on \"The Tracey Ullman Show\" for three seasons, the Simpson family received their own series on Fox, which debuted December 17, 1989.']],\n",
       "   ['Bart Simpson',\n",
       "    ['Bartholomew JoJo \"Bart\" Simpson is a fictional character in the American animated television series \"The Simpsons\" and part of the Simpson family.',\n",
       "     ' He is voiced by Nancy Cartwright and first appeared on television in \"The Tracey Ullman Show\" short \"Good Night\" on April 19, 1987.',\n",
       "     \" Cartoonist Matt Groening created and designed Bart while waiting in the lobby of James L. Brooks' office.\",\n",
       "     ' Groening had been called to pitch a series of shorts based on his comic strip, \"Life in Hell\", but instead decided to create a new set of characters.',\n",
       "     ' While the rest of the characters were named after Groening\\'s family members, Bart\\'s name is an anagram of the word \"brat\".',\n",
       "     ' After appearing on \"The Tracey Ullman Show\" for three years, the Simpson family received its own series on Fox, which debuted December 17, 1989.']],\n",
       "   ['Allie Goertz',\n",
       "    ['Allison Beth \"Allie\" Goertz (born March 2, 1991) is an American musician.',\n",
       "     ' Goertz is known for her satirical songs based on various pop culture topics.',\n",
       "     ' Her videos are posted on YouTube under the name of Cossbysweater.',\n",
       "     ' Subjects of her songs have included the film \"The Room\", the character Milhouse from the television show \"The Simpsons\", and the game Dungeons & Dragons.',\n",
       "     ' Her style has been compared to that of Bo Burnham.',\n",
       "     ' In December 2015, Goertz released a concept album based on the Adult Swim series \"Rick and Morty\", \"Sad Dance Songs\", with the album\\'s cover emulating the animation and logo of the series.',\n",
       "     ' The album was made possible through Kickstarter.',\n",
       "     \" She is co-host of Everything's Coming Up Podcast, a Simpsons-focused podcast along with Julia Prescott.\"]],\n",
       "   ['Milhouse Van Houten',\n",
       "    ['Milhouse Mussolini van Houten is a fictional character featured in the animated television series \"The Simpsons\", voiced by Pamela Hayden, and created by Matt Groening who named the character after President Richard Nixon\\'s middle name.',\n",
       "     ' Later in the series, it is revealed that Milhouse\\'s middle name is \"Mussolini.\"']],\n",
       "   ['Los Angeles Reader',\n",
       "    ['Los Angeles Reader was a weekly paper established in 1978 and distributed in Los Angeles, United States.',\n",
       "     ' It followed the format of the (still active) Chicago Reader.',\n",
       "     ' The paper was known for having lengthy, thoughtful reviews of movies, plays and concerts in the LA area.',\n",
       "     ' James Vowell was its founding editor.',\n",
       "     \" Among its writers were Keith Fitzgerald, Nigey Lennon, Lionel Rolfe, Lawrence Wechsler, Mick Farren, Richard Meltzer, Heidi Dvorak, Chris Morris, Jerry Stahl, Steven Kane, Andy Klein, Allen Levy, Jim Goad, Kirk Silsbee, Henry Sheehan, Samantha Dunn, Natalie Nichols, Steve Appleford, Eric Mankin (also editor), Paul Birchall, Eddie Rivera (who wrote the paper's first cover story), Amy Steinberg, Harry Sheehan, Dan Sallit, Myron Meisel, David Ehrenstein.\",\n",
       "     ' Tom Davis, Bruce Bebb, Stuart Goldman, Ernest Hardy, Kevin Uhrich, Erik Himmelsbach and David L. Ulin.',\n",
       "     \" It is famous for being the first newspaper to publish Matt Groening's cartoon strip, Life in Hell on April 25, 1980.\",\n",
       "     ' James Vowell hired Matt Groening as his assistant editor in 1979.',\n",
       "     ' Groening was also originally a Reader music critic.',\n",
       "     ' It also ran a cartoon strip by David Lynch (director of Blue Velvet) called The Angriest Dog in the World, a strip notable for having exactly the same drawing panels for its entire run.',\n",
       "     ' James Vowell and his wife Codette Wallace bought the Reader from the Chicago Reader in February 1989.',\n",
       "     ' They sold \"The Reader\" to New Times Media in 1996, which merged it with the \"Los Angeles View\" to form \"New Times LA\".']],\n",
       "   ['Homer Simpson',\n",
       "    ['Homer Jay Simpson is a fictional character and the main protagonist of the American animated television series \"The Simpsons\" as the patriarch of the eponymous family.',\n",
       "     ' He is voiced by Dan Castellaneta and first appeared on television, along with the rest of his family, in \"The Tracey Ullman Show\" short \"Good Night\" on April 19, 1987.',\n",
       "     \" Homer was created and designed by cartoonist Matt Groening while he was waiting in the lobby of James L. Brooks' office.\",\n",
       "     ' Groening had been called to pitch a series of shorts based on his comic strip \"Life in Hell\" but instead decided to create a new set of characters.',\n",
       "     ' He named the character after his father, Homer Groening.',\n",
       "     ' After appearing for three seasons on \"The Tracey Ullman Show\", the Simpson family got their own series on Fox that debuted December 17, 1989.']],\n",
       "   ['List of The Simpsons video games',\n",
       "    ['\"The Simpsons\" is an American animated television sitcom created by Matt Groening for the Fox Broadcasting Company.',\n",
       "     ' The series is a satirical parody of a middle class American lifestyle epitomized by its eponymous family, which consists of Homer, Marge, Bart, Lisa and Maggie.',\n",
       "     ' It is set in the fictional town of Springfield, and lampoons American culture, society and television, and many aspects of the human condition.',\n",
       "     ' The family was conceived by Groening shortly before a pitch for a series of animated shorts with producer James L.\\xa0Brooks.',\n",
       "     ' Groening created a dysfunctional family and named the characters after members of his own family, substituting Bart for his own name.',\n",
       "     ' The shorts became a part of \"The Tracey Ullman Show\" on April 19, 1987 and after a three-season run, the sketch was developed into a half-hour prime time show and became a hit series for Fox.',\n",
       "     ' The growing popularity of the series motivated video game developers to create video games based on the series.',\n",
       "     ' Two pinball machines have also been produced; one self-titled, that was only made available for a limited time after the first season finale (1990) and \"The Simpsons Pinball Party\" (2003).',\n",
       "     ' Additionally, several handheld device games have been released, such as \"Bartman: Avenger of Evil\" (1990) and \"Bart Simpson\\'s Cupcake Crisis\" (1991).']],\n",
       "   ['The Simpsons: An Uncensored, Unauthorized History',\n",
       "    ['The Simpsons: An Uncensored, Unauthorized History is a non-fiction book about the American animated television series \"The Simpsons\".',\n",
       "     ' It was written by John Ortved, and first published in October 2009 by Faber and Faber.',\n",
       "     \" In the United Kingdom, the book is called Simpsons Confidential: The uncensored, totally unauthorised history of the world's greatest TV show by the people that made it.\",\n",
       "     ' The book is an oral history of the show, and concentrates particularly on the writers and producers of the show.',\n",
       "     ' The book includes entire chapters devoted to key figures such as creator Matt Groening and James L. Brooks and Sam Simon, who helped develop the series.',\n",
       "     ' According to National Public Radio reviewer Linda Holmes, \"Ortved\\'s thesis, essentially, is that lots of people are responsible for the success of \"The Simpsons\", and their creator, Matt Groening, has too often been viewed as the sole source to the detriment of others who also deserve to be praised.\"']],\n",
       "   ['List of The Simpsons guest stars',\n",
       "    ['In addition to the show\\'s regular cast of voice actors, celebrity guest stars have been a staple of \"The Simpsons\", an American animated television sitcom created by Matt Groening for the Fox Broadcasting Company, since its first season.',\n",
       "     ' \"The Simpsons\" focuses on the eponymous family, which consists of Homer, Marge, Bart, Lisa and Maggie.',\n",
       "     ' The family was initially conceived by Groening for a series of animated shorts, which originally aired as a part of \"The Tracey Ullman Show\" between 1987 and 1989.',\n",
       "     ' The shorts were developed into a half-hour prime time series which began in December 1989.',\n",
       "     ' The series\\' 27th season began in September 2015 and episodes of \"The Simpsons\" have aired.',\n",
       "     ' A feature film adaptation of the series called \"The Simpsons Movie\", was released in 2007.']]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_rawrom_file = ParagraphSelector(model_path=parent_dir + '/models/paragraphSelector_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
