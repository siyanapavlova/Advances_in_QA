{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installations done before\n",
    "    \n",
    "    pip3 install pytorch-pretrained-bert\n",
    "    pip3 install pytorch-nlp\n",
    "    pip3 install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "from utils import HotPotDataHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model=BertModel.from_pretrained('bert-base-uncased',\n",
    "                                 output_hidden_states=True,\n",
    "                                 output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text,\n",
    "           tokenizer=BertTokenizer.from_pretrained('bert-base-uncased'),\n",
    "           model=BertModel.from_pretrained('bert-base-uncased',\n",
    "                                 output_hidden_states=True,\n",
    "                                 output_attentions=True)):\n",
    "    ''' TODO: document\n",
    "    '''\n",
    "    \n",
    "    input_ids = torch.tensor([tokenizer.encode(text)])\n",
    "    all_hidden_states, all_attentions = model(input_ids)[-2:]\n",
    "    \n",
    "    # This is the embedding of the [CLS] token.\n",
    "    # [-1] is the last hidden state (list of sentences)\n",
    "    # first [0] - first (and only) sentence\n",
    "    # second [0] - first ([CLS]) token of the sentence\n",
    "    return all_hidden_states[-1][0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paragraph Selector Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module implements the Paragraph Selector from the paper, Section 3.1\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class ParagraphSelector():\n",
    "    \"\"\"\n",
    "    TODO: write docstring\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 model_path=None,\n",
    "                 tokenizer=None,\n",
    "                 model=None):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \"\"\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') if not tokenizer else tokenizer\n",
    "        self.model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                 output_hidden_states=True,\n",
    "                                 output_attentions=True) if not model else model\n",
    "        \n",
    "        class ParagraphSelectorNet(torch.nn.Module):\n",
    "            \"\"\"\n",
    "            TODO: write docstring\n",
    "            \"\"\"\n",
    "            def __init__(self, input_size=768, output_size=1):\n",
    "                super(ParagraphSelectorNet, self).__init__()\n",
    "                self.linear  = torch.nn.Linear(input_size, output_size)\n",
    "\n",
    "            def forward(self, embedding):\n",
    "                output = self.linear(embedding)\n",
    "                output = torch.sigmoid(output)\n",
    "\n",
    "                return output \n",
    "            \n",
    "        self.net = ParagraphSelectorNet()\n",
    "        if model_path:\n",
    "            try:\n",
    "                self.net.load_state_dict(torch.load(model_path))\n",
    "            except FileNotFoundError as e:\n",
    "                print(e, model_path)\n",
    "    \n",
    "    def encode(self, text):\n",
    "        ''' TODO: document\n",
    "        '''\n",
    "\n",
    "        input_ids = torch.tensor([self.tokenizer.encode(text)])\n",
    "        all_hidden_states, all_attentions = self.model(input_ids)[-2:]\n",
    "\n",
    "        # This is the embedding of the [CLS] token.\n",
    "        # [-1] is the last hidden state (list of sentences)\n",
    "        # first [0] - first (and only) sentence\n",
    "        # second [0] - first ([CLS]) token of the sentence\n",
    "        return all_hidden_states[-1][0][0]\n",
    "\n",
    "    def train(self, train_data, labels, epochs, learning_rate=0.0001):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \"\"\"\n",
    "        # Use Binary Cross Entropy as a loss function instead of MSE\n",
    "        # There are papers on why MSE is bad for classification\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), lr=learning_rate)\n",
    "\n",
    "        losses = []\n",
    "        \n",
    "        # Set the network into train mode\n",
    "        self.net.train()\n",
    "\n",
    "        print(\"Training...\")\n",
    "\n",
    "        # Iterate over the epochs\n",
    "        for epoch in range(epochs):\n",
    "            print('Epoch %d/%d' % (epoch + 1, epochs))\n",
    "            for inputs, label in zip(train_data, labels):\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.net(inputs)\n",
    "                loss = criterion(outputs, label)\n",
    "                loss.backward(retain_graph=True)\n",
    "                losses.append(loss.item())\n",
    "                optimizer.step()\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def predict(self, p):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \"\"\"\n",
    "        self.net.eval()\n",
    "        score = self.net(p)\n",
    "        return score\n",
    "\n",
    "    def evaluate(self, data, threshold=0.1):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \"\"\"\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        \n",
    "        for point in data:\n",
    "            context = self.make_context(point, threshold) #point[2] are the paragrphs, point[1] is the query\n",
    "            for para in point[2]:\n",
    "                y_true.append(para[0] in point[0])\n",
    "                y_pred.append(para in context)\n",
    "        \n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        \n",
    "        return precision, recall\n",
    "    \n",
    "    def make_context(self, datapoint, threshold=0.1):\n",
    "        \"\"\"\n",
    "        TODO: write docstring\n",
    "        \n",
    "        Parameters: paragraphs - [[p1_title, [p1_s1, p1_s2 ...]],\n",
    "                                  [p2_title, [p2_s1, p2_s2, ...]],\n",
    "                                   ...]\n",
    "                    query - the query as a string\n",
    "                    threshold - a float between zero and one;\n",
    "                                paragraphs that get a score above the\n",
    "                                threshold, become part of the context\n",
    "        Output: context: [[p1_title, [p1_s1, p1_s2 ...]],\n",
    "                          [p2_title, [p2_s1, p2_s2, ...]],\n",
    "                           ...]\n",
    "        \"\"\"\n",
    "        context = []\n",
    "        for p in datapoint[2]:\n",
    "            # p[0] is the paragraph title, p[1] is the list of sentences in the paragraph\n",
    "            encoded_p = self.encode(\"[CLS] \" + datapoint[1] + \" [SEP] \" + (\"\").join(p[1]) + \" [SEP]\")\n",
    "            score = self.predict(encoded_p)\n",
    "            if score > threshold:\n",
    "                context.append(p)\n",
    "        return context\n",
    "    \n",
    "    def save(self, savepath):\n",
    "        '''\n",
    "        TODO: write docstring\n",
    "        '''\n",
    "        directory_name = \"/\".join(savepath.split('/')[:-1])\n",
    "        print(directory_name)\n",
    "        if not os.path.exists(directory_name):\n",
    "            os.makedirs(directory_name)\n",
    "        torch.save(self.net.state_dict(), savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = HotPotDataHandler(parent_dir + \"/data/hotpot_train_v1.1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dh.data_for_paragraph_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_data(data,\n",
    "                       tokenizer=BertTokenizer.from_pretrained('bert-base-uncased'),\n",
    "                       model=BertModel.from_pretrained('bert-base-uncased',\n",
    "                                 output_hidden_states=True,\n",
    "                                 output_attentions=True)):\n",
    "    '''\n",
    "    Make a dataframe with training data for selecting relevant paragraphs\n",
    "    Each entry in the dataframe has three columns:\n",
    "        1. Query - the question\n",
    "        2. Paragraphs - the paragraphs\n",
    "        3. Label - 0 (unrelated) or 1 (related)\n",
    "    '''\n",
    "    labels = []\n",
    "    datapoints = []\n",
    "    for point in data:        \n",
    "        for para in point[2]:\n",
    "            labels.append(torch.Tensor([int(para[0] in point[0])])) # Label 1: if paragraph title is in supporting facts, otherwise 0\n",
    "            encoded_point = encode(\"[CLS] \" + point[1] + \" [SEP] \" + (\"\").join(para[1]) + \" [SEP]\", tokenizer, model)\n",
    "            datapoints.append(encoded_point)\n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "        'id': range(len(labels)),\n",
    "        'label': labels,\n",
    "        'text': datapoints\n",
    "    })\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_raw, test_data_raw = train_test_split(data[:4], test_size=0.25, random_state=42, shuffle=True)\n",
    "training_data = make_training_data(training_data_raw)\n",
    "training_data = shuffle(training_data, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.0142, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "      <td>[tensor(-0.4818, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "      <td>[tensor(-0.0365, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "      <td>[tensor(-0.4297, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.8046, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.5943, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.3586, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "      <td>[tensor(-0.3114, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.1670, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.1817, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "      <td>[tensor(-0.6894, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.6392, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[tensor(1.)]</td>\n",
       "      <td>[tensor(-0.3911, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(0.2380, grad_fn=&lt;SelectBackward&gt;), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.0445, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.1094, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(0.1476, grad_fn=&lt;SelectBackward&gt;), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.6847, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.6722, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.3263, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.1060, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.0798, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(0.2227, grad_fn=&lt;SelectBackward&gt;), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(0.1563, grad_fn=&lt;SelectBackward&gt;), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.0921, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.4255, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.7114, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.6326, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(0.0597, grad_fn=&lt;SelectBackward&gt;), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[tensor(0.)]</td>\n",
       "      <td>[tensor(-0.4104, grad_fn=&lt;SelectBackward&gt;), te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id         label                                               text\n",
       "27  27  [tensor(0.)]  [tensor(-0.0142, grad_fn=<SelectBackward>), te...\n",
       "15  15  [tensor(1.)]  [tensor(-0.4818, grad_fn=<SelectBackward>), te...\n",
       "23  23  [tensor(1.)]  [tensor(-0.0365, grad_fn=<SelectBackward>), te...\n",
       "17  17  [tensor(1.)]  [tensor(-0.4297, grad_fn=<SelectBackward>), te...\n",
       "8    8  [tensor(0.)]  [tensor(-0.8046, grad_fn=<SelectBackward>), te...\n",
       "9    9  [tensor(0.)]  [tensor(-0.5943, grad_fn=<SelectBackward>), te...\n",
       "28  28  [tensor(0.)]  [tensor(-0.3586, grad_fn=<SelectBackward>), te...\n",
       "24  24  [tensor(1.)]  [tensor(-0.3114, grad_fn=<SelectBackward>), te...\n",
       "12  12  [tensor(0.)]  [tensor(-0.1670, grad_fn=<SelectBackward>), te...\n",
       "0    0  [tensor(0.)]  [tensor(-0.1817, grad_fn=<SelectBackward>), te...\n",
       "4    4  [tensor(1.)]  [tensor(-0.6894, grad_fn=<SelectBackward>), te...\n",
       "16  16  [tensor(0.)]  [tensor(-0.6392, grad_fn=<SelectBackward>), te...\n",
       "5    5  [tensor(1.)]  [tensor(-0.3911, grad_fn=<SelectBackward>), te...\n",
       "13  13  [tensor(0.)]  [tensor(0.2380, grad_fn=<SelectBackward>), ten...\n",
       "11  11  [tensor(0.)]  [tensor(-0.0445, grad_fn=<SelectBackward>), te...\n",
       "22  22  [tensor(0.)]  [tensor(-0.1094, grad_fn=<SelectBackward>), te...\n",
       "1    1  [tensor(0.)]  [tensor(0.1476, grad_fn=<SelectBackward>), ten...\n",
       "2    2  [tensor(0.)]  [tensor(-0.6847, grad_fn=<SelectBackward>), te...\n",
       "25  25  [tensor(0.)]  [tensor(-0.6722, grad_fn=<SelectBackward>), te...\n",
       "3    3  [tensor(0.)]  [tensor(-0.3263, grad_fn=<SelectBackward>), te...\n",
       "21  21  [tensor(0.)]  [tensor(-0.1060, grad_fn=<SelectBackward>), te...\n",
       "26  26  [tensor(0.)]  [tensor(-0.0798, grad_fn=<SelectBackward>), te...\n",
       "18  18  [tensor(0.)]  [tensor(0.2227, grad_fn=<SelectBackward>), ten...\n",
       "29  29  [tensor(0.)]  [tensor(0.1563, grad_fn=<SelectBackward>), ten...\n",
       "20  20  [tensor(0.)]  [tensor(-0.0921, grad_fn=<SelectBackward>), te...\n",
       "7    7  [tensor(0.)]  [tensor(-0.4255, grad_fn=<SelectBackward>), te...\n",
       "10  10  [tensor(0.)]  [tensor(-0.7114, grad_fn=<SelectBackward>), te...\n",
       "14  14  [tensor(0.)]  [tensor(-0.6326, grad_fn=<SelectBackward>), te...\n",
       "19  19  [tensor(0.)]  [tensor(0.0597, grad_fn=<SelectBackward>), ten...\n",
       "6    6  [tensor(0.)]  [tensor(-0.4104, grad_fn=<SelectBackward>), te..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = ParagraphSelector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "losses = ps.train(training_data[\"text\"], training_data[\"label\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 1.0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.evaluate(test_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Splitting data...\n",
      "Initilising ParagraphSelector...\n",
      "Training...\n",
      "Epoch 1/1\n",
      "Evaluating...\n",
      "Precision: 0.2\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading data...\")\n",
    "dh = HotPotDataHandler(parent_dir + \"/data/hotpot_train_v1.1.json\")\n",
    "data = dh.data_for_paragraph_selector()\n",
    "\n",
    "print(\"Splitting data...\")\n",
    "training_data_raw, test_data_raw = train_test_split(data[:4], test_size=0.25, random_state=42, shuffle=True)\n",
    "training_data = make_training_data(training_data_raw)\n",
    "training_data = shuffle(training_data, random_state=42)\n",
    "\n",
    "print(\"Initilising ParagraphSelector...\")\n",
    "ps = ParagraphSelector()\n",
    "losses = ps.train(training_data[\"text\"], training_data[\"label\"], 1)\n",
    "\n",
    "print(\"Evaluating...\")\n",
    "precision, recall = ps.evaluate(test_data_raw)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/siyana/Github/Advances_in_QA/models\n"
     ]
    }
   ],
   "source": [
    "ps.save(parent_dir + '/models/paragraphSelector_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_from_file = ParagraphSelector(model_path=parent_dir + '/models/paragraphSelector_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
