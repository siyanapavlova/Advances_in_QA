# this config is for locally running the DFGN pipeline.
# Here are some hints towards parameter names:
# 'ps' = paragraph selector
# 'fb' = facebook (jk lol it's actually 'fusion block')

# absolute path to the directory in which the model outputs are (model, times, losses etc.)
model_abs_dir       '/home/simon/Desktop/LCT_Saarbrücken/Courses/AQA/data_in_QA/models/'

# FOR TRAINING ON THE WHOLE DATASET
data_abs_path       '/home/simon/Desktop/LCT_Saarbrücken/Courses/AQA/project_AQA/data/hotpot_train_v1.1.json'
dev_data_abs_path   '/home/simon/Desktop/LCT_Saarbrücken/Courses/AQA/project_AQA/data/hotpot_dev_distractor_v1.json'

# FOR TRAINING ON SMALL AMOUNTS OF DATA
# leave this unspecified if training on the whole data set
pickled_train_data   '/home/simon/Desktop/LCT_Saarbrücken/Courses/AQA/project_AQA/data/pickled/train'
pickled_dev_data     '/home/simon/Desktop/LCT_Saarbrücken/Courses/AQA/project_AQA/data/pickled/dev'


# PARAGRAPH SELECTOR
# for loading a previously trained paragraph selector model
ps_model_abs_path       "/home/simon/Desktop/LCT_Saarbrücken/Courses/AQA/data_in_QA/models/"
ps_threshold        0.1

# ENTITY GRAPH
tagger_device       'cpu'

# ENCODER
# used throughout DFGN
text_length     250
emb_size  300

# FUSION BLOCK
fb_passes           1

# PREDICTOR
# coefficients (section 3.5)
lambda_s            0.5
lambda_t            0.5


# HYPERPARAMETERS
try_training_on_gpu     False

# number of questions for training/evaluation
dataset_size         10
# this should be 0.01 for the big run (in order to have 1000 questions for eval. during training)
percent_for_eval_during_training      0.20
shuffle_seed    42


epochs              1
# number of questions per batch
batch_size          1
learning_rate       0.0001
eval_interval       10000

