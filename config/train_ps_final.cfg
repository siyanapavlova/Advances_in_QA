# This config is for training the paragraph selector with an 80-20 train/test
# split.

# file names of the model and the results are given as arguments at execution time
#data_abs_path       /local/simonp/data/hotpotqa/hotpot_train_v1.1.json
data_abs_path       '/local/simonp/data/hotpot_train_v1.1.json'
dev_data_abs_path   '/local/simonp/data/hotpot_dev_distractor_v1.json'
# this is also used to output the losses and training time
model_abs_dir       '/local/simonp/AQA/data_in_QA/models/'
#data_abs_path       /home/simon/Desktop/LCT_Saarbrücken/Courses/AQA/project_AQA/data/hotpot_dev_distractor_v1.json
#model_abs_dir       /home/simon/Desktop/LCT_Saarbrücken/Courses/AQA/tmp/

# use this for convenience if running on smaller subsets of the data (e.g. during preliminary tests)
#pickled_train_data   '/local/simonp/data/pickled/train'
#pickled_dev_data     '/local/simonp/data/pickled/dev'

# according to the documentation, it can be one of multiple forms, including a shortcut
bert_model_path     'bert-base-uncased'


# This configuration is for running on jones-5

# each data point contains 10 paragraphs (= 10 training examples)
# leave dataset_size unspecified to take the whole dataset
#dataset_size    10000
percent_for_eval_during_training      0.01
#dev_data_limit  1000 #CLEANUP
#test_split      0.20 #CLEANUP
shuffle_seed    42
# evaluate training progress every ___ paragraphs
eval_interval    100000
#eval_interval   10000 # this was for preliminary tests
# limits paragraph length in order to reduce complexity
text_length     250

epochs          3
#epochs          1 # this was for preliminary tests
batch_size      16
# default is 1e-4
learning_rate   1e-5

